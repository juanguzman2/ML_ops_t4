{
  "pipelineSpec": {
    "components": {
      "comp-prediction": {
        "executorLabel": "exec-prediction",
        "inputDefinitions": {
          "parameters": {
            "features_table": {
              "type": "STRING"
            },
            "path_model": {
              "type": "STRING"
            },
            "project": {
              "type": "STRING"
            },
            "source_x_train_table": {
              "type": "STRING"
            },
            "table_id": {
              "type": "STRING"
            }
          }
        }
      }
    },
    "deploymentSpec": {
      "executors": {
        "exec-prediction": {
          "container": {
            "args": [
              "--executor_input",
              "{{$}}",
              "--function_to_execute",
              "prediction"
            ],
            "command": [
              "sh",
              "-c",
              "\nif ! [ -x \"$(command -v pip)\" ]; then\n    python3 -m ensurepip || python3 -m ensurepip --user || apt-get install python3-pip\nfi\n\nPIP_DISABLE_PIP_VERSION_CHECK=1 python3 -m pip install --quiet     --no-warn-script-location 'google-cloud-bigquery' 'google-cloud-bigquery-storage' 'pandas' 'scikit-learn' 'joblib' 'db-dtypes' 'pyarrow' 'pandas-gbq' 'google-cloud-storage' 'pytz' 'kfp==1.8.21' && \"$0\" \"$@\"\n",
              "sh",
              "-ec",
              "program_path=$(mktemp -d)\nprintf \"%s\" \"$0\" > \"$program_path/ephemeral_component.py\"\npython3 -m kfp.v2.components.executor_main                         --component_module_path                         \"$program_path/ephemeral_component.py\"                         \"$@\"\n",
              "\nimport kfp\nfrom kfp.v2 import dsl\nfrom kfp.v2.dsl import *\nfrom typing import *\n\ndef prediction(\n    project: str,\n    source_x_train_table: str,\n    features_table: str,\n    table_id: str,\n    path_model: str,\n):  \n    import sys\n    from datetime import datetime\n    import pandas as pd\n    from google.cloud import bigquery\n    from google.auth import default\n    import pandas_gbq\n    from google.cloud import storage\n    from joblib import load\n    from io import BytesIO\n    from pytz import timezone\n\n    TZ = timezone('America/Lima')\n    FORMAT_DATE = \"%Y-%m-%d\"\n\n    # Cliente BigQuery\n    client = bigquery.Client(project=project)\n\n    # Leer datos de BigQuery\n    X_train = client.query(\n    '''SELECT * FROM `{dsource_table}`\n        '''.format(dsource_table=source_x_train_table)).to_dataframe()\n\n\n    # Leer caracter\u00edsticas seleccionadas de BigQuery\n    features = client.query(\n    '''SELECT * FROM `{dsource_table}`\n        '''.format(dsource_table=features_table)).to_dataframe()\n\n    features = features[\"string_field_0\"].tolist()\n\n\n    X_train = X_train[features]\n\n    def generate_datetime_created():\n        return datetime.now()\n\n    def generate_date_created():\n        return datetime.now(TZ).date().strftime(FORMAT_DATE)\n\n\n    def load_model_from_gcs(path_model):\n        # Inicializar el cliente de Cloud Storage\n        storage_client = storage.Client()\n\n        # Obtener el nombre del bucket y la ruta del objeto\n        bucket_name, blob_name = path_model.replace(\"gs://\", \"\").split(\"/\", 1)\n\n        # Obtener el objeto desde Cloud Storage\n        bucket = storage_client.bucket(bucket_name)\n        blob = bucket.blob(blob_name)\n        model_bytes = blob.download_as_string()\n\n        # Cargar el modelo desde los bytes obtenidos\n        classifier = load(BytesIO(model_bytes))\n\n        return classifier\n\n    classifier = load_model_from_gcs(path_model)\n\n    # Realizar la predicci\u00f3n\n    predictions = classifier.predict(X_train)\n    predictions = pd.DataFrame(predictions, columns=['prediction'])\n\n    # Obtener el user_id de la sesi\u00f3n actual en BigQuery\n    user_id = client.query(\"SELECT SESSION_USER()\").to_dataframe().iloc[0, 0]\n\n    # Agregar campos de auditor\u00eda\n    start_time = generate_datetime_created()\n    execute_date = generate_date_created()\n\n    predictions['creation_user'] = user_id\n    predictions['process_date'] = datetime.strptime(execute_date, '%Y-%m-%d')\n    predictions['process_date'] = pd.to_datetime(predictions['process_date']).dt.date\n    predictions['load_date'] = pd.to_datetime(start_time)\n\n    # Guardar el resultado en BigQuery \n    pandas_gbq.to_gbq(predictions , table_id, if_exists='append', project_id=project)\n\n    print(\"Predicci\u00f3n generada y guardada en BigQuery.\")\n\n"
            ],
            "image": "python:3.7"
          }
        }
      }
    },
    "pipelineInfo": {
      "name": "pipeline-prediction-model"
    },
    "root": {
      "dag": {
        "tasks": {
          "prediction": {
            "cachingOptions": {
              "enableCache": true
            },
            "componentRef": {
              "name": "comp-prediction"
            },
            "inputs": {
              "parameters": {
                "features_table": {
                  "componentInputParameter": "features_table"
                },
                "path_model": {
                  "componentInputParameter": "path_model"
                },
                "project": {
                  "componentInputParameter": "project"
                },
                "source_x_train_table": {
                  "componentInputParameter": "source_x_train_table"
                },
                "table_id": {
                  "componentInputParameter": "table_id"
                }
              }
            },
            "taskInfo": {
              "name": "PREDICTION_MODEL"
            }
          }
        }
      },
      "inputDefinitions": {
        "parameters": {
          "features_table": {
            "type": "STRING"
          },
          "gcp_region": {
            "type": "STRING"
          },
          "path_model": {
            "type": "STRING"
          },
          "project": {
            "type": "STRING"
          },
          "source_x_train_table": {
            "type": "STRING"
          },
          "table_id": {
            "type": "STRING"
          }
        }
      }
    },
    "schemaVersion": "2.0.0",
    "sdkVersion": "kfp-1.8.21"
  },
  "runtimeConfig": {
    "gcsOutputDirectory": "gs://diabetes-bucket1/demo",
    "parameters": {
      "gcp_region": {
        "stringValue": "us-central1"
      }
    }
  }
}